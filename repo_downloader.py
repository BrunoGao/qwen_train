#!/usr/bin/env python3
"""
Qwen2.5ä»£ç è®­ç»ƒä»“åº“è‡ªåŠ¨ä¸‹è½½è„šæœ¬
æ”¯æŒä»JSONé…ç½®æ–‡ä»¶æ‰¹é‡ä¸‹è½½GitHubä»“åº“ï¼ŒåŒ…å«è¿›åº¦æ˜¾ç¤ºã€æ–­ç‚¹ç»­ä¼ ã€æ–‡ä»¶è¿‡æ»¤ç­‰åŠŸèƒ½
"""

import json
import os
import sys
import subprocess
import shutil
import time
import logging
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Optional
import argparse
from dataclasses import dataclass
from tqdm import tqdm

@dataclass
class RepoInfo:
    """ä»“åº“ä¿¡æ¯æ•°æ®ç±»"""
    id: int
    name: str
    full_name: str
    url: str
    language: str
    stars: str
    priority: str
    code_quality_score: float

class RepoDownloader:
    """ä»“åº“ä¸‹è½½å™¨ä¸»ç±»"""
    
    def __init__(self, config_file: str = "qwen25_code_training_repositories.json", 
                 output_dir: str = "repositories", max_workers: int = 4):
        self.config_file = config_file
        self.output_dir = Path(output_dir)
        self.max_workers = max_workers
        self.setup_logging()
        self.setup_directories()
        self.repos = []
        self.failed_repos = []
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('repo_download.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def setup_directories(self):
        """åˆ›å»ºç›®å½•ç»“æ„"""
        self.output_dir.mkdir(exist_ok=True)
        (self.output_dir / "high_priority").mkdir(exist_ok=True)
        (self.output_dir / "medium_priority").mkdir(exist_ok=True)
        (self.output_dir / "logs").mkdir(exist_ok=True)
        
    def load_repositories(self) -> List[RepoInfo]:
        """åŠ è½½ä»“åº“é…ç½®"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            repos = []
            for repo_data in data['repositories']:
                repo = RepoInfo(
                    id=repo_data['id'],
                    name=repo_data['name'],
                    full_name=repo_data['full_name'],
                    url=repo_data['url'],
                    language=repo_data['language'],
                    stars=repo_data['stars'],
                    priority=repo_data['priority'],
                    code_quality_score=repo_data['code_quality_score']
                )
                repos.append(repo)
            
            self.logger.info(f"æˆåŠŸåŠ è½½ {len(repos)} ä¸ªä»“åº“é…ç½®")
            return repos
            
        except FileNotFoundError:
            self.logger.error(f"é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨")
            sys.exit(1)
        except json.JSONDecodeError as e:
            self.logger.error(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            sys.exit(1)
            
    def check_git_available(self) -> bool:
        """æ£€æŸ¥Gitæ˜¯å¦å¯ç”¨"""
        try:
            subprocess.run(['git', '--version'], capture_output=True, check=True)
            return True
        except (subprocess.CalledProcessError, FileNotFoundError):
            self.logger.error("Gitæœªå®‰è£…æˆ–ä¸å¯ç”¨ï¼Œè¯·å…ˆå®‰è£…Git")
            return False
            
    def check_git_lfs_available(self) -> bool:
        """æ£€æŸ¥Git LFSæ˜¯å¦å¯ç”¨"""
        try:
            subprocess.run(['git', 'lfs', 'version'], capture_output=True, check=True)
            return True
        except (subprocess.CalledProcessError, FileNotFoundError):
            self.logger.warning("Git LFSæœªå®‰è£…ï¼Œå¤§æ–‡ä»¶å¯èƒ½æ— æ³•æ­£ç¡®ä¸‹è½½")
            return False
            
    def get_repo_path(self, repo: RepoInfo) -> Path:
        """è·å–ä»“åº“æœ¬åœ°è·¯å¾„"""
        priority_dir = "high_priority" if repo.priority == "HIGH" else "medium_priority"
        return self.output_dir / priority_dir / repo.language.lower() / repo.name
        
    def is_repo_exists(self, repo_path: Path) -> bool:
        """æ£€æŸ¥ä»“åº“æ˜¯å¦å·²å­˜åœ¨"""
        return repo_path.exists() and (repo_path / ".git").exists()
        
    def clone_repository(self, repo: RepoInfo, retry_count: int = 3) -> bool:
        """å…‹éš†å•ä¸ªä»“åº“"""
        repo_path = self.get_repo_path(repo)
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if self.is_repo_exists(repo_path):
            self.logger.info(f"ä»“åº“ {repo.full_name} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
            return True
            
        # åˆ›å»ºç›®å½•
        repo_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ„å»ºgit cloneå‘½ä»¤
        cmd = [
            'git', 'clone',
            '--depth=1',  # æµ…å…‹éš†ï¼ŒèŠ‚çœç©ºé—´å’Œæ—¶é—´
            '--single-branch',
            repo.url,
            str(repo_path)
        ]
        
        for attempt in range(retry_count):
            try:
                self.logger.info(f"æ­£åœ¨ä¸‹è½½ {repo.full_name} (å°è¯• {attempt + 1}/{retry_count})")
                
                process = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    universal_newlines=True,
                    bufsize=1
                )
                
                # å®æ—¶è¾“å‡ºè¿›åº¦
                for line in process.stdout:
                    if "Receiving objects" in line or "Resolving deltas" in line:
                        print(f"\r{repo.name}: {line.strip()}", end="", flush=True)
                        
                process.wait()
                
                if process.returncode == 0:
                    print()  # æ¢è¡Œ
                    self.logger.info(f"âœ… {repo.full_name} ä¸‹è½½å®Œæˆ")
                    
                    # æ¸…ç†ä¸éœ€è¦çš„æ–‡ä»¶
                    self.cleanup_repository(repo_path)
                    return True
                else:
                    self.logger.warning(f"âŒ {repo.full_name} ä¸‹è½½å¤±è´¥ï¼Œè¿”å›ç : {process.returncode}")
                    
            except Exception as e:
                self.logger.error(f"ä¸‹è½½ {repo.full_name} æ—¶å‡ºé”™: {e}")
                
            # æ¸…ç†å¤±è´¥çš„å…‹éš†
            if repo_path.exists():
                shutil.rmtree(repo_path, ignore_errors=True)
                
            if attempt < retry_count - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                
        return False
        
    def cleanup_repository(self, repo_path: Path):
        """æ¸…ç†ä»“åº“ä¸­ä¸éœ€è¦çš„æ–‡ä»¶"""
        cleanup_patterns = [
            "**/.git/objects/pack/*.pack",  # å¤§çš„packæ–‡ä»¶
            "**/node_modules",
            "**/target/debug",
            "**/target/release", 
            "**/build",
            "**/dist",
            "**/*.pyc",
            "**/__pycache__",
            "**/test/fixtures/**/*.dat",
            "**/docs/images/**/*.png",
            "**/docs/images/**/*.jpg"
        ]
        
        for pattern in cleanup_patterns:
            for file_path in repo_path.glob(pattern):
                try:
                    if file_path.is_file():
                        file_path.unlink()
                    elif file_path.is_dir():
                        shutil.rmtree(file_path, ignore_errors=True)
                except Exception as e:
                    self.logger.debug(f"æ¸…ç†æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
                    
    def get_repo_size(self, repo_path: Path) -> float:
        """è·å–ä»“åº“å¤§å°(MB)"""
        total_size = 0
        for file_path in repo_path.rglob("*"):
            if file_path.is_file():
                try:
                    total_size += file_path.stat().st_size
                except (OSError, FileNotFoundError):
                    pass
        return total_size / (1024 * 1024)  # è½¬æ¢ä¸ºMB
        
    def download_repos_parallel(self, repos: List[RepoInfo]) -> Dict[str, List[RepoInfo]]:
        """å¹¶è¡Œä¸‹è½½ä»“åº“"""
        successful = []
        failed = []
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_repo = {
                executor.submit(self.clone_repository, repo): repo 
                for repo in repos
            }
            
            with tqdm(total=len(repos), desc="ä¸‹è½½è¿›åº¦", unit="repo") as pbar:
                for future in as_completed(future_to_repo):
                    repo = future_to_repo[future]
                    try:
                        success = future.result()
                        if success:
                            successful.append(repo)
                        else:
                            failed.append(repo)
                    except Exception as e:
                        self.logger.error(f"ä¸‹è½½ {repo.full_name} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                        failed.append(repo)
                    finally:
                        pbar.update(1)
                        
        return {"successful": successful, "failed": failed}
        
    def generate_report(self, results: Dict[str, List[RepoInfo]]):
        """ç”Ÿæˆä¸‹è½½æŠ¥å‘Š"""
        successful = results["successful"]
        failed = results["failed"]
        
        report = {
            "summary": {
                "total_repos": len(successful) + len(failed),
                "successful": len(successful),
                "failed": len(failed),
                "success_rate": f"{len(successful)/(len(successful)+len(failed))*100:.1f}%",
                "download_time": time.strftime("%Y-%m-%d %H:%M:%S")
            },
            "successful_repos": [
                {
                    "name": repo.full_name,
                    "language": repo.language,
                    "priority": repo.priority,
                    "local_path": str(self.get_repo_path(repo)),
                    "size_mb": round(self.get_repo_size(self.get_repo_path(repo)), 2)
                } for repo in successful
            ],
            "failed_repos": [
                {
                    "name": repo.full_name,
                    "language": repo.language,
                    "priority": repo.priority,
                    "url": repo.url
                } for repo in failed
            ]
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.output_dir / "logs" / f"download_report_{int(time.time())}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
            
        # æ‰“å°æ‘˜è¦
        print("\n" + "="*50)
        print("ğŸ“Š ä¸‹è½½å®ŒæˆæŠ¥å‘Š")
        print("="*50)
        print(f"æ€»ä»“åº“æ•°: {report['summary']['total_repos']}")
        print(f"æˆåŠŸä¸‹è½½: {report['summary']['successful']} âœ…")
        print(f"ä¸‹è½½å¤±è´¥: {report['summary']['failed']} âŒ") 
        print(f"æˆåŠŸç‡: {report['summary']['success_rate']}")
        print(f"æŠ¥å‘Šä¿å­˜è‡³: {report_file}")
        
        if failed:
            print(f"\nâŒ å¤±è´¥çš„ä»“åº“:")
            for repo in failed:
                print(f"  - {repo.full_name}")
                
        total_size = sum(repo_data['size_mb'] for repo_data in report['successful_repos'])
        print(f"\nğŸ’¾ æ€»ä¸‹è½½å¤§å°: {total_size:.1f} MB")
        
    def run(self, priority_filter: Optional[str] = None, language_filter: Optional[str] = None):
        """è¿è¡Œä¸‹è½½å™¨"""
        print("ğŸš€ Qwen2.5ä»£ç è®­ç»ƒä»“åº“è‡ªåŠ¨ä¸‹è½½å™¨")
        print("="*50)
        
        # æ£€æŸ¥ä¾èµ–
        if not self.check_git_available():
            return False
            
        self.check_git_lfs_available()
        
        # åŠ è½½ä»“åº“é…ç½®
        all_repos = self.load_repositories()
        
        # åº”ç”¨è¿‡æ»¤å™¨
        repos_to_download = all_repos
        if priority_filter:
            repos_to_download = [r for r in repos_to_download if r.priority == priority_filter]
            print(f"ğŸ” ä¼˜å…ˆçº§è¿‡æ»¤: {priority_filter}")
            
        if language_filter:
            repos_to_download = [r for r in repos_to_download if r.language.lower() == language_filter.lower()]
            print(f"ğŸ” è¯­è¨€è¿‡æ»¤: {language_filter}")
            
        print(f"ğŸ“¦ å‡†å¤‡ä¸‹è½½ {len(repos_to_download)} ä¸ªä»“åº“")
        print(f"ğŸ’¾ ä¸‹è½½ç›®å½•: {self.output_dir.absolute()}")
        print(f"ğŸ”„ å¹¶å‘æ•°: {self.max_workers}")
        
        # å¼€å§‹ä¸‹è½½
        start_time = time.time()
        results = self.download_repos_parallel(repos_to_download)
        end_time = time.time()
        
        print(f"\nâ±ï¸ æ€»è€—æ—¶: {end_time - start_time:.1f} ç§’")
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report(results)
        
        return len(results["failed"]) == 0

def main():
    parser = argparse.ArgumentParser(description="Qwen2.5ä»£ç è®­ç»ƒä»“åº“è‡ªåŠ¨ä¸‹è½½å™¨")
    parser.add_argument("--config", "-c", default="qwen25_code_training_repositories.json",
                       help="é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: qwen25_code_training_repositories.json)")
    parser.add_argument("--output", "-o", default="repositories",
                       help="è¾“å‡ºç›®å½• (é»˜è®¤: repositories)")
    parser.add_argument("--workers", "-w", type=int, default=4,
                       help="å¹¶å‘ä¸‹è½½æ•° (é»˜è®¤: 4)")
    parser.add_argument("--priority", "-p", choices=["HIGH", "MEDIUM"],
                       help="åªä¸‹è½½æŒ‡å®šä¼˜å…ˆçº§çš„ä»“åº“")
    parser.add_argument("--language", "-l", 
                       help="åªä¸‹è½½æŒ‡å®šè¯­è¨€çš„ä»“åº“ (Python/Java/C++/Go/Rust)")
    parser.add_argument("--dry-run", action="store_true",
                       help="è¯•è¿è¡Œï¼Œåªæ˜¾ç¤ºå°†è¦ä¸‹è½½çš„ä»“åº“åˆ—è¡¨")
    
    args = parser.parse_args()
    
    if args.dry_run:
        # è¯•è¿è¡Œæ¨¡å¼
        downloader = RepoDownloader(args.config, args.output, args.workers)
        repos = downloader.load_repositories()
        
        if args.priority:
            repos = [r for r in repos if r.priority == args.priority]
        if args.language:
            repos = [r for r in repos if r.language.lower() == args.language.lower()]
            
        print(f"ğŸ” å°†è¦ä¸‹è½½çš„ä»“åº“ ({len(repos)} ä¸ª):")
        for repo in repos:
            print(f"  - {repo.full_name} ({repo.language}, {repo.priority}, {repo.stars})")
        return
        
    # æ­£å¸¸è¿è¡Œ
    downloader = RepoDownloader(args.config, args.output, args.workers)
    success = downloader.run(args.priority, args.language)
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
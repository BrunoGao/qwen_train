#!/usr/bin/env python3
"""
Qwen 2.5 Code A40 å®Œæ•´è®­ç»ƒæ‰§è¡Œè„šæœ¬
æ•´åˆæ‰€æœ‰ç»„ä»¶çš„ä¸»è®­ç»ƒå…¥å£
"""

import os
import sys
import json
import argparse
import logging
from pathlib import Path
from typing import Dict, Any, Optional

import torch
import transformers
from transformers import set_seed, AutoTokenizer, AutoModelForCausalLM
import deepspeed

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from data_preprocessing import process_repositories, save_dataset
from train_qwen_code import main as train_main
from evaluation import run_comprehensive_evaluation
from checkpoint_manager import CheckpointManager


def setup_logging(log_dir: str = "/codes/logs"):
    """è®¾ç½®æ—¥å¿—"""
    Path(log_dir).mkdir(parents=True, exist_ok=True)
    
    log_file = Path(log_dir) / "training.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info("Logging initialized")
    return logger


def check_environment():
    """æ£€æŸ¥è®­ç»ƒç¯å¢ƒ"""
    logger = logging.getLogger(__name__)
    
    # æ£€æŸ¥CUDA
    if not torch.cuda.is_available():
        raise RuntimeError("CUDA is not available")
    
    gpu_count = torch.cuda.device_count()
    logger.info(f"Found {gpu_count} GPUs")
    
    for i in range(gpu_count):
        gpu_name = torch.cuda.get_device_name(i)
        gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
        logger.info(f"GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
    
    # æ£€æŸ¥å…³é”®ä¾èµ–
    try:
        import flash_attn
        logger.info(f"Flash Attention: {flash_attn.__version__}")
    except ImportError:
        logger.warning("Flash Attention not available")
    
    logger.info(f"PyTorch: {torch.__version__}")
    logger.info(f"Transformers: {transformers.__version__}")
    logger.info(f"DeepSpeed: {deepspeed.__version__}")
    
    return True


def validate_paths(args):
    """éªŒè¯è·¯å¾„é…ç½®"""
    logger = logging.getLogger(__name__)
    
    # æ£€æŸ¥æ¨¡å‹è·¯å¾„
    if args.model_path and not Path(args.model_path).exists():
        raise FileNotFoundError(f"Model path not found: {args.model_path}")
    
    # æ£€æŸ¥æ•°æ®è·¯å¾„
    if args.data_path:
        data_path = Path(args.data_path)
        if not data_path.exists():
            logger.warning(f"Data path not found: {data_path}, will create during preprocessing")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(args.output_dir).mkdir(parents=True, exist_ok=True)
    
    logger.info("Path validation completed")


def run_data_preprocessing(args) -> str:
    """è¿è¡Œæ•°æ®é¢„å¤„ç†"""
    logger = logging.getLogger(__name__)
    logger.info("Starting data preprocessing...")
    
    try:
        # å¤„ç†ä»“åº“æ•°æ®
        dataset = process_repositories()
        
        # ä¿å­˜æ•°æ®é›†
        processed_data_path = args.data_path or "/codes/processed_training_data"
        stats = save_dataset(dataset, processed_data_path)
        
        logger.info(f"Data preprocessing completed: {stats['total_samples']} samples")
        return processed_data_path
        
    except Exception as e:
        logger.error(f"Data preprocessing failed: {e}")
        raise


def run_training(args, data_path: str):
    """è¿è¡Œè®­ç»ƒ"""
    logger = logging.getLogger(__name__)
    logger.info("Starting model training...")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ.update({
        'CUDA_VISIBLE_DEVICES': args.gpu_ids,
        'PYTORCH_CUDA_ALLOC_CONF': 'max_split_size_mb:128',
        'TOKENIZERS_PARALLELISM': 'false'
    })
    
    # æ„å»ºè®­ç»ƒå‚æ•°
    training_args = [
        "--model_name_or_path", args.model_path,
        "--data_path", data_path,
        "--output_dir", args.output_dir,
        "--num_train_epochs", str(args.epochs),
        "--per_device_train_batch_size", str(args.batch_size),
        "--gradient_accumulation_steps", str(args.gradient_accumulation_steps),
        "--learning_rate", str(args.learning_rate),
        "--save_steps", str(args.save_steps),
        "--logging_steps", str(args.logging_steps),
        "--bf16", "true",
        "--gradient_checkpointing", "true",
        "--dataloader_num_workers", "4",
        "--remove_unused_columns", "false",
        "--deepspeed", "/codes/deepspeed_config.json"
    ]
    
    if args.use_wandb:
        training_args.extend([
            "--report_to", "wandb",
            "--run_name", f"qwen-code-{args.run_name or 'default'}"
        ])
    
    # ä¿å­˜åŸå§‹å‚æ•°
    original_argv = sys.argv.copy()
    
    try:
        # æ›¿æ¢å‘½ä»¤è¡Œå‚æ•°
        sys.argv = ["train_qwen_code.py"] + training_args
        
        # è¿è¡Œè®­ç»ƒ
        train_main()
        
        logger.info("Training completed successfully")
        
    except Exception as e:
        logger.error(f"Training failed: {e}")
        raise
    finally:
        # æ¢å¤åŸå§‹å‚æ•°
        sys.argv = original_argv


def run_evaluation(args):
    """è¿è¡Œæ¨¡å‹è¯„ä¼°"""
    logger = logging.getLogger(__name__)
    logger.info("Starting model evaluation...")
    
    try:
        # æŸ¥æ‰¾æœ€æ–°çš„æ¨¡å‹
        model_path = args.output_dir
        if not Path(model_path).exists():
            raise FileNotFoundError(f"Trained model not found: {model_path}")
        
        # è¿è¡Œè¯„ä¼°
        results = run_comprehensive_evaluation(
            model_path=model_path,
            output_dir=Path(args.output_dir) / "evaluation"
        )
        
        logger.info("Model evaluation completed")
        return results
        
    except Exception as e:
        logger.error(f"Evaluation failed: {e}")
        raise


def generate_training_report(args, training_time: float, evaluation_results: Optional[Dict] = None):
    """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
    logger = logging.getLogger(__name__)
    
    report = {
        "training_info": {
            "model_name": "Qwen2.5-7B-Code",
            "base_model": args.model_path,
            "training_time_hours": round(training_time / 3600, 2),
            "epochs": args.epochs,
            "batch_size": args.batch_size,
            "learning_rate": args.learning_rate,
            "gpu_config": args.gpu_ids,
            "output_dir": args.output_dir
        },
        "system_info": {
            "gpu_count": torch.cuda.device_count(),
            "pytorch_version": torch.__version__,
            "transformers_version": transformers.__version__,
        }
    }
    
    if evaluation_results:
        report["evaluation_results"] = {
            "code_understanding": evaluation_results.get('code_understanding', {}).get('score', 0),
            "code_generation": evaluation_results.get('code_generation', {}).get('score', 0),
            "performance": evaluation_results.get('performance', {})
        }
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = Path(args.output_dir) / "training_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    logger.info(f"Training report saved to: {report_path}")
    
    # æ‰“å°æ‘˜è¦
    print("\n" + "="*60)
    print("ğŸ‰ TRAINING COMPLETED SUCCESSFULLY!")
    print("="*60)
    print(f"ğŸ“Š Training Time: {report['training_info']['training_time_hours']} hours")
    print(f"ğŸ’¾ Model Output: {args.output_dir}")
    if evaluation_results:
        print(f"ğŸ§  Code Understanding: {report['evaluation_results']['code_understanding']:.2f}")
        print(f"âš¡ Code Generation: {report['evaluation_results']['code_generation']:.2f}")
    print(f"ğŸ“‹ Full Report: {report_path}")
    print("="*60)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Qwen 2.5 Code A40 Training Pipeline")
    
    # æ¨¡å‹å’Œæ•°æ®é…ç½®
    parser.add_argument("--model_path", type=str, required=True, help="Base model path")
    parser.add_argument("--data_path", type=str, help="Processed data path (will create if not exists)")
    parser.add_argument("--output_dir", type=str, default="/codes/outputs", help="Output directory")
    
    # è®­ç»ƒé…ç½®
    parser.add_argument("--epochs", type=int, default=3, help="Number of training epochs")
    parser.add_argument("--batch_size", type=int, default=2, help="Batch size per GPU")
    parser.add_argument("--gradient_accumulation_steps", type=int, default=8, help="Gradient accumulation steps")
    parser.add_argument("--learning_rate", type=float, default=2e-5, help="Learning rate")
    parser.add_argument("--save_steps", type=int, default=1000, help="Save checkpoint every N steps")
    parser.add_argument("--logging_steps", type=int, default=100, help="Logging every N steps")
    
    # ç³»ç»Ÿé…ç½®
    parser.add_argument("--gpu_ids", type=str, default="0,1,2,3,4,5,6,7", help="GPU IDs to use")
    parser.add_argument("--seed", type=int, default=42, help="Random seed")
    
    # è¿è¡Œé…ç½®
    parser.add_argument("--skip_preprocessing", action="store_true", help="Skip data preprocessing")
    parser.add_argument("--skip_training", action="store_true", help="Skip training")
    parser.add_argument("--skip_evaluation", action="store_true", help="Skip evaluation")
    parser.add_argument("--use_wandb", action="store_true", help="Use Weights & Biases logging")
    parser.add_argument("--run_name", type=str, help="Run name for logging")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging()
    
    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)
    
    try:
        # ç¯å¢ƒæ£€æŸ¥
        logger.info("Checking environment...")
        check_environment()
        
        # è·¯å¾„éªŒè¯
        logger.info("Validating paths...")
        validate_paths(args)
        
        start_time = time.time()
        
        # 1. æ•°æ®é¢„å¤„ç†
        data_path = args.data_path
        if not args.skip_preprocessing:
            data_path = run_data_preprocessing(args)
        elif not data_path:
            data_path = "/codes/processed_training_data"
            if not Path(data_path).exists():
                raise FileNotFoundError(f"Data path not found and preprocessing skipped: {data_path}")
        
        # 2. æ¨¡å‹è®­ç»ƒ
        if not args.skip_training:
            run_training(args, data_path)
        
        # 3. æ¨¡å‹è¯„ä¼°
        evaluation_results = None
        if not args.skip_evaluation:
            evaluation_results = run_evaluation(args)
        
        # 4. ç”ŸæˆæŠ¥å‘Š
        training_time = time.time() - start_time
        generate_training_report(args, training_time, evaluation_results)
        
    except KeyboardInterrupt:
        logger.info("Training interrupted by user")
        sys.exit(1)
    except Exception as e:
        logger.error(f"Training pipeline failed: {e}")
        sys.exit(1)


if __name__ == "__main__":
    import time
    main()
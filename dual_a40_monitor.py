#!/usr/bin/env python3
"""
åŒA40è®­ç»ƒç›‘æ§å’Œæ£€æŸ¥ç‚¹ç®¡ç†å™¨
ä¸“é—¨é’ˆå¯¹åŒGPUç¯å¢ƒä¼˜åŒ–çš„ç›‘æ§ç³»ç»Ÿ
"""

import os
import json
import time
import psutil
import subprocess
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
import threading
import queue
import signal

import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForCausalLM


@dataclass
class DualA40Metrics:
    """åŒA40ç›‘æ§æŒ‡æ ‡"""
    timestamp: str
    step: int
    epoch: float
    loss: float
    learning_rate: float
    gpu_0_memory_gb: float
    gpu_1_memory_gb: float
    gpu_0_utilization: int
    gpu_1_utilization: int
    gpu_0_temperature: int
    gpu_1_temperature: int
    cpu_percent: float
    memory_percent: float
    throughput_samples_per_sec: float
    gradient_norm: float
    eta_hours: float


class DualA40Monitor:
    """åŒA40è®­ç»ƒç›‘æ§å™¨"""
    
    def __init__(self, output_dir: str, checkpoint_interval: int = 1000):
        self.output_dir = Path(output_dir)
        self.checkpoint_interval = checkpoint_interval
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç›‘æ§æ–‡ä»¶
        self.metrics_file = self.output_dir / "training_metrics.jsonl"
        self.alerts_file = self.output_dir / "alerts.log"
        
        # ç›‘æ§çŠ¶æ€
        self.monitoring = False
        self.metrics_queue = queue.Queue()
        self.start_time = time.time()
        self.last_checkpoint_time = time.time()
        
        # æ€§èƒ½å†å²
        self.step_history = []
        self.loss_history = []
        self.memory_history = []
        
        # é˜ˆå€¼è®¾ç½®
        self.memory_threshold = 45  # GB
        self.temperature_threshold = 80  # æ‘„æ°åº¦
        self.utilization_min = 70  # æœ€å°GPUåˆ©ç”¨ç‡
        
        print(f"ğŸ“Š Dual A40 Monitor initialized")
        print(f"ğŸ“ Output: {output_dir}")

    def get_gpu_metrics(self) -> Dict[str, Any]:
        """è·å–GPUæŒ‡æ ‡"""
        gpu_metrics = {}
        
        try:
            # ä½¿ç”¨nvidia-ml-pyæˆ–nvidia-smi
            result = subprocess.run([
                'nvidia-smi', '--query-gpu=index,memory.used,memory.total,utilization.gpu,temperature.gpu',
                '--format=csv,noheader,nounits'
            ], capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                for i, line in enumerate(lines[:2]):  # åªå–å‰ä¸¤ä¸ªGPU
                    parts = line.split(', ')
                    if len(parts) >= 5:
                        gpu_metrics[f'gpu_{i}'] = {
                            'memory_used_mb': int(parts[1]),
                            'memory_total_mb': int(parts[2]),
                            'memory_used_gb': round(int(parts[1]) / 1024, 2),
                            'utilization_percent': int(parts[3]),
                            'temperature_celsius': int(parts[4])
                        }
        except Exception as e:
            print(f"âš ï¸ GPU metrics collection failed: {e}")
        
        # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨PyTorch
        if not gpu_metrics and torch.cuda.is_available():
            for i in range(min(torch.cuda.device_count(), 2)):
                try:
                    memory_allocated = torch.cuda.memory_allocated(i)
                    memory_reserved = torch.cuda.memory_reserved(i)
                    gpu_metrics[f'gpu_{i}'] = {
                        'memory_used_gb': round(memory_allocated / 1024**3, 2),
                        'memory_reserved_gb': round(memory_reserved / 1024**3, 2),
                        'utilization_percent': 0,  # æ— æ³•é€šè¿‡PyTorchè·å–
                        'temperature_celsius': 0   # æ— æ³•é€šè¿‡PyTorchè·å–
                    }
                except Exception:
                    pass
        
        return gpu_metrics

    def get_system_metrics(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸæŒ‡æ ‡"""
        try:
            cpu_percent = psutil.cpu_percent(interval=0.1)
            memory = psutil.virtual_memory()
            
            return {
                'cpu_percent': round(cpu_percent, 1),
                'memory_percent': round(memory.percent, 1),
                'memory_used_gb': round(memory.used / 1024**3, 2),
                'memory_total_gb': round(memory.total / 1024**3, 2)
            }
        except Exception as e:
            print(f"âš ï¸ System metrics collection failed: {e}")
            return {}

    def calculate_throughput(self, current_step: int) -> float:
        """è®¡ç®—è®­ç»ƒååé‡"""
        if len(self.step_history) < 2:
            return 0.0
        
        # ä½¿ç”¨æœ€è¿‘10ä¸ªæ­¥éª¤è®¡ç®—å¹³å‡é€Ÿåº¦
        recent_steps = self.step_history[-10:]
        if len(recent_steps) >= 2:
            time_diff = recent_steps[-1]['time'] - recent_steps[0]['time']
            step_diff = recent_steps[-1]['step'] - recent_steps[0]['step']
            
            if time_diff > 0:
                return round(step_diff / time_diff, 4)
        
        return 0.0

    def record_metrics(self, training_metrics: Dict[str, Any]):
        """è®°å½•è®­ç»ƒæŒ‡æ ‡"""
        current_time = time.time()
        timestamp = datetime.now().isoformat()
        
        # è·å–ç³»ç»ŸæŒ‡æ ‡
        gpu_metrics = self.get_gpu_metrics()
        system_metrics = self.get_system_metrics()
        
        # æ›´æ–°å†å²è®°å½•
        step = training_metrics.get('step', 0)
        loss = training_metrics.get('loss', 0.0)
        
        self.step_history.append({'time': current_time, 'step': step})
        self.loss_history.append({'time': current_time, 'loss': loss})
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†å¤§å°
        if len(self.step_history) > 100:
            self.step_history = self.step_history[-50:]
        if len(self.loss_history) > 100:
            self.loss_history = self.loss_history[-50:]
        
        # è®¡ç®—ååé‡
        throughput = self.calculate_throughput(step)
        
        # ä¼°ç®—å‰©ä½™æ—¶é—´
        eta_hours = 0.0
        if throughput > 0 and 'max_steps' in training_metrics:
            remaining_steps = training_metrics['max_steps'] - step
            eta_seconds = remaining_steps / throughput
            eta_hours = round(eta_seconds / 3600, 2)
        
        # æ„å»ºå®Œæ•´æŒ‡æ ‡
        metrics = DualA40Metrics(
            timestamp=timestamp,
            step=step,
            epoch=training_metrics.get('epoch', 0.0),
            loss=loss,
            learning_rate=training_metrics.get('learning_rate', 0.0),
            gpu_0_memory_gb=gpu_metrics.get('gpu_0', {}).get('memory_used_gb', 0.0),
            gpu_1_memory_gb=gpu_metrics.get('gpu_1', {}).get('memory_used_gb', 0.0),
            gpu_0_utilization=gpu_metrics.get('gpu_0', {}).get('utilization_percent', 0),
            gpu_1_utilization=gpu_metrics.get('gpu_1', {}).get('utilization_percent', 0),
            gpu_0_temperature=gpu_metrics.get('gpu_0', {}).get('temperature_celsius', 0),
            gpu_1_temperature=gpu_metrics.get('gpu_1', {}).get('temperature_celsius', 0),
            cpu_percent=system_metrics.get('cpu_percent', 0.0),
            memory_percent=system_metrics.get('memory_percent', 0.0),
            throughput_samples_per_sec=throughput,
            gradient_norm=training_metrics.get('gradient_norm', 0.0),
            eta_hours=eta_hours
        )
        
        # ä¿å­˜æŒ‡æ ‡
        with open(self.metrics_file, 'a') as f:
            f.write(json.dumps(asdict(metrics)) + '\n')
        
        # æ£€æŸ¥å¼‚å¸¸
        self.check_alerts(metrics, gpu_metrics, system_metrics)
        
        # æ‰“å°è¿›åº¦
        self.print_progress(metrics)
        
        return metrics

    def check_alerts(self, metrics: DualA40Metrics, gpu_metrics: Dict, system_metrics: Dict):
        """æ£€æŸ¥å¼‚å¸¸æƒ…å†µå¹¶è®°å½•è­¦æŠ¥"""
        alerts = []
        
        # GPUå†…å­˜æ£€æŸ¥
        if metrics.gpu_0_memory_gb > self.memory_threshold:
            alerts.append(f"GPU 0 memory high: {metrics.gpu_0_memory_gb:.1f}GB")
        if metrics.gpu_1_memory_gb > self.memory_threshold:
            alerts.append(f"GPU 1 memory high: {metrics.gpu_1_memory_gb:.1f}GB")
        
        # GPUæ¸©åº¦æ£€æŸ¥
        if metrics.gpu_0_temperature > self.temperature_threshold:
            alerts.append(f"GPU 0 temperature high: {metrics.gpu_0_temperature}Â°C")
        if metrics.gpu_1_temperature > self.temperature_threshold:
            alerts.append(f"GPU 1 temperature high: {metrics.gpu_1_temperature}Â°C")
        
        # GPUåˆ©ç”¨ç‡æ£€æŸ¥
        if metrics.gpu_0_utilization < self.utilization_min and metrics.gpu_0_utilization > 0:
            alerts.append(f"GPU 0 utilization low: {metrics.gpu_0_utilization}%")
        if metrics.gpu_1_utilization < self.utilization_min and metrics.gpu_1_utilization > 0:
            alerts.append(f"GPU 1 utilization low: {metrics.gpu_1_utilization}%")
        
        # ç³»ç»Ÿå†…å­˜æ£€æŸ¥
        if metrics.memory_percent > 90:
            alerts.append(f"System memory high: {metrics.memory_percent:.1f}%")
        
        # Lossæ£€æŸ¥
        if len(self.loss_history) >= 10:
            recent_losses = [h['loss'] for h in self.loss_history[-10:]]
            if all(loss > recent_losses[0] for loss in recent_losses[5:]):
                alerts.append("Loss not decreasing in recent steps")
        
        # è®°å½•è­¦æŠ¥
        if alerts:
            timestamp = datetime.now().isoformat()
            with open(self.alerts_file, 'a') as f:
                for alert in alerts:
                    f.write(f"[{timestamp}] âš ï¸ {alert}\n")
                    print(f"âš ï¸ ALERT: {alert}")

    def print_progress(self, metrics: DualA40Metrics):
        """æ‰“å°è®­ç»ƒè¿›åº¦"""
        if metrics.step % 50 == 0:  # æ¯50æ­¥æ‰“å°ä¸€æ¬¡
            gpu_mem = f"GPU: {metrics.gpu_0_memory_gb:.1f}GB/{metrics.gpu_1_memory_gb:.1f}GB"
            gpu_util = f"Util: {metrics.gpu_0_utilization}%/{metrics.gpu_1_utilization}%"
            
            print(f"Step {metrics.step} | Loss: {metrics.loss:.4f} | {gpu_mem} | {gpu_util} | "
                  f"Speed: {metrics.throughput_samples_per_sec:.3f} steps/s | ETA: {metrics.eta_hours:.1f}h")

    def should_save_checkpoint(self, step: int, force: bool = False) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¿å­˜æ£€æŸ¥ç‚¹"""
        if force:
            return True
        
        # æŒ‰æ­¥æ•°é—´éš”
        if step % self.checkpoint_interval == 0:
            return True
        
        # æŒ‰æ—¶é—´é—´éš” (æ¯å°æ—¶)
        current_time = time.time()
        if current_time - self.last_checkpoint_time > 3600:
            self.last_checkpoint_time = current_time
            return True
        
        return False

    def get_training_summary(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒæ‘˜è¦"""
        if not self.step_history or not self.loss_history:
            return {"message": "No training data available"}
        
        current_time = time.time()
        training_time = current_time - self.start_time
        
        # åŸºæœ¬ç»Ÿè®¡
        steps = [h['step'] for h in self.step_history]
        losses = [h['loss'] for h in self.loss_history]
        
        summary = {
            "training_time_hours": round(training_time / 3600, 2),
            "total_steps": max(steps) if steps else 0,
            "current_loss": losses[-1] if losses else 0,
            "best_loss": min(losses) if losses else 0,
            "avg_throughput": self.calculate_throughput(max(steps) if steps else 0),
            "gpu_memory_usage": {
                "max_gpu_0": max([float(line.split()[12]) for line in open(self.metrics_file, 'r') 
                                if line.strip() and 'gpu_0_memory_gb' in line] or [0]),
                "max_gpu_1": max([float(line.split()[14]) for line in open(self.metrics_file, 'r') 
                                if line.strip() and 'gpu_1_memory_gb' in line] or [0])
            }
        }
        
        return summary

    def cleanup_old_metrics(self, keep_hours: int = 48):
        """æ¸…ç†æ—§çš„ç›‘æ§æ•°æ®"""
        if not self.metrics_file.exists():
            return
        
        cutoff_time = datetime.now() - timedelta(hours=keep_hours)
        
        # è¯»å–ç°æœ‰æ•°æ®
        valid_lines = []
        with open(self.metrics_file, 'r') as f:
            for line in f:
                try:
                    data = json.loads(line.strip())
                    timestamp = datetime.fromisoformat(data['timestamp'])
                    if timestamp > cutoff_time:
                        valid_lines.append(line)
                except:
                    continue
        
        # é‡å†™æ–‡ä»¶
        with open(self.metrics_file, 'w') as f:
            f.writelines(valid_lines)
        
        print(f"ğŸ—‘ï¸ Cleaned old metrics, kept {len(valid_lines)} records")


def create_dual_a40_monitoring_dashboard():
    """åˆ›å»ºåŒA40ç›‘æ§ä»ªè¡¨æ¿HTML"""
    html_content = """
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dual A40 Training Monitor</title>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .metric-box { 
            display: inline-block; 
            background: #f5f5f5; 
            padding: 15px; 
            margin: 10px; 
            border-radius: 5px; 
            min-width: 150px;
        }
        .metric-value { font-size: 24px; font-weight: bold; color: #2c3e50; }
        .metric-label { font-size: 14px; color: #7f8c8d; }
        .alert { background: #ffebee; border-left: 4px solid #f44336; padding: 10px; margin: 10px 0; }
        .chart { width: 100%; height: 400px; margin: 20px 0; }
    </style>
</head>
<body>
    <h1>ğŸš€ Qwen 2.5 7B Code - Dual A40 Training Monitor</h1>
    
    <div id="metrics">
        <div class="metric-box">
            <div class="metric-value" id="current-loss">--</div>
            <div class="metric-label">Current Loss</div>
        </div>
        <div class="metric-box">
            <div class="metric-value" id="gpu-0-memory">--</div>
            <div class="metric-label">GPU 0 Memory (GB)</div>
        </div>
        <div class="metric-box">
            <div class="metric-value" id="gpu-1-memory">--</div>
            <div class="metric-label">GPU 1 Memory (GB)</div>
        </div>
        <div class="metric-box">
            <div class="metric-value" id="throughput">--</div>
            <div class="metric-label">Steps/sec</div>
        </div>
        <div class="metric-box">
            <div class="metric-value" id="eta">--</div>
            <div class="metric-label">ETA (hours)</div>
        </div>
    </div>
    
    <div id="alerts"></div>
    
    <div id="loss-chart" class="chart"></div>
    <div id="memory-chart" class="chart"></div>
    <div id="gpu-util-chart" class="chart"></div>
    
    <script>
        // æ¨¡æ‹Ÿæ•°æ®æ›´æ–°
        function updateDashboard() {
            // è¿™é‡Œåº”è¯¥ä»å®é™…çš„metricsæ–‡ä»¶è¯»å–æ•°æ®
            console.log('Updating dashboard...');
        }
        
        // æ¯30ç§’æ›´æ–°ä¸€æ¬¡
        setInterval(updateDashboard, 30000);
        updateDashboard();
    </script>
</body>
</html>
"""
    
    dashboard_path = "/codes/dual_a40_dashboard.html"
    with open(dashboard_path, 'w') as f:
        f.write(html_content)
    
    print(f"ğŸ“Š Dashboard created: {dashboard_path}")
    return dashboard_path


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Dual A40 Training Monitor")
    parser.add_argument("--output_dir", default="/codes/outputs", help="Output directory")
    parser.add_argument("--create_dashboard", action="store_true", help="Create HTML dashboard")
    
    args = parser.parse_args()
    
    # åˆ›å»ºç›‘æ§å™¨
    monitor = DualA40Monitor(args.output_dir)
    
    if args.create_dashboard:
        create_dual_a40_monitoring_dashboard()
    
    # ç¤ºä¾‹ï¼šæ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡æ›´æ–°
    print("ğŸ”„ Monitor ready. Press Ctrl+C to stop.")
    
    try:
        step = 0
        while True:
            # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡
            training_metrics = {
                'step': step,
                'epoch': step / 1000,
                'loss': 3.0 - (step * 0.001),
                'learning_rate': 1.5e-5,
                'gradient_norm': 0.8,
                'max_steps': 50000
            }
            
            metrics = monitor.record_metrics(training_metrics)
            
            step += 1
            time.sleep(10)  # æ¯10ç§’æ›´æ–°ä¸€æ¬¡
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ Monitor stopped by user")
        summary = monitor.get_training_summary()
        print("\nğŸ“Š Training Summary:")
        print(json.dumps(summary, indent=2))